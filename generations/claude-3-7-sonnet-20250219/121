def create_matrix(rows: int, cols: int, fill_value=0) -> list:
    """
    Creates a matrix of size rows x cols, filled with fill_value.
    
    Parameters:
    rows (int): number of rows.
    cols (int): number of columns.
    fill_value (any type): value to fill the matrix.
    
    Returns:
    list: matrix as a list of lists.
    """
    return [[fill_value for _ in range(cols)] for _ in range(rows)]


def add_matrices(matrix_a: list, matrix_b: list) -> list:
    """
    Adds two matrices of the same size.
    
    Parameters:
    matrix_a (list): first matrix.
    matrix_b (list): second matrix.
    
    Returns:
    list: result of matrix addition.
    """
    # Check if the matrices have the same dimensions
    rows_a = len(matrix_a)
    cols_a = len(matrix_a[0])
    rows_b = len(matrix_b)
    cols_b = len(matrix_b[0])
    
    if rows_a != rows_b or cols_a != cols_b:
        raise ValueError("Matrices must have the same dimensions for addition")
    
    # Perform element-wise addition
    result = create_matrix(rows_a, cols_a)
    for i in range(rows_a):
        for j in range(cols_a):
            result[i][j] = matrix_a[i][j] + matrix_b[i][j]
    
    return result


def scalar_multiply(matrix: list, scalar: float) -> list:
    """
    Multiplies all elements of a matrix by a scalar.
    
    Parameters:
    matrix (list): original matrix.
    scalar (float): number by which matrix elements are multiplied.
    
    Returns:
    list: result of matrix scalar multiplication.
    """
    rows = len(matrix)
    cols = len(matrix[0])
    
    result = create_matrix(rows, cols)
    for i in range(rows):
        for j in range(cols):
            result[i][j] = matrix[i][j] * scalar
    
    return result


def multiply_matrices(matrix_a: list, matrix_b: list) -> list:
    """
    Multiplies two matrices.
    
    Parameters:
    matrix_a (list): first matrix.
    matrix_b (list): second matrix.
    
    Returns:
    list: result of matrix multiplication.
    """
    # Check if matrices can be multiplied
    rows_a = len(matrix_a)
    cols_a = len(matrix_a[0])
    rows_b = len(matrix_b)
    cols_b = len(matrix_b[0])
    
    if cols_a != rows_b:
        raise ValueError("Number of columns in first matrix must equal number of rows in second matrix")
    
    # Create result matrix and perform multiplication
    result = create_matrix(rows_a, cols_b)
    for i in range(rows_a):
        for j in range(cols_b):
            for k in range(cols_a):  # or rows_b, they're the same
                result[i][j] += matrix_a[i][k] * matrix_b[k][j]
    
    return result


def transpose_matrix(matrix: list) -> list:
    """
    Transposes a matrix.
    
    Parameters:
    matrix (list): original matrix.
    
    Returns:
    list: transposed matrix.
    """
    rows = len(matrix)
    cols = len(matrix[0])
    
    # Create a new matrix with swapped dimensions
    result = create_matrix(cols, rows)
    for i in range(rows):
        for j in range(cols):
            result[j][i] = matrix[i][j]
    
    return result


def determinant_3x3(matrix: list) -> float:
    """
    Calculates the determinant of a 3x3 matrix.
    
    Parameters:
    matrix (list): original 3x3 matrix.
    
    Returns:
    float: determinant of the matrix.
    """
    # Check if the matrix is 3x3
    if len(matrix) != 3 or any(len(row) != 3 for row in matrix):
        raise ValueError("Input must be a 3x3 matrix")
    
    # Using the formula: det(A) = a11(a22a33 - a23a32) - a12(a21a33 - a23a31) + a13(a21a32 - a22a31)
    a11, a12, a13 = matrix[0]
    a21, a22, a23 = matrix[1]
    a31, a32, a33 = matrix[2]
    
    term1 = a11 * (a22 * a33 - a23 * a32)
    term2 = a12 * (a21 * a33 - a23 * a31)
    term3 = a13 * (a21 * a32 - a22 * a31)
    
    return term1 - term2 + term3