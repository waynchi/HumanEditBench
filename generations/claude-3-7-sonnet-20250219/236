import numpy as np
from matplotlib import pyplot as plt
from scipy.stats import lognorm
from scipy.optimize import minimize
from scipy.integrate import quad
import pandas as pd
from tqdm import tqdm
from typing import Dict, List, Tuple
import json
import pandas as pd


class ModelRouter:
    def __init__(
        self,
        models: List[str],
        lambda_latency: float = 1.0,
        lambda_rarity: float = 1.0,
        lambda_ambiguity: float = 1.0,
    ):
        self.models = models
        self.n_models = len(models)
        self.model_to_idx = {model: idx for idx, model in enumerate(models)}
        self.lambda_latency = lambda_latency
        self.lambda_rarity = lambda_rarity
        self.lambda_ambiguity = lambda_ambiguity

        # 初始化参数
        self.n_pairs = (self.n_models * (self.n_models - 1)) // 2
        self.theta = np.zeros(self.n_pairs)

        # 战斗统计的缓存
        self.battle_counts = None
        self.battle_preferences = None

        # 延迟参数的缓存
        self.latency_params = None

    def _softmax_function(self, theta: np.ndarray, temp: float = 1.0) -> np.ndarray:
        """使用带温度的softmax将参数转换为概率。"""
        exp_theta = np.exp(theta / temp)
        return exp_theta / np.sum(exp_theta)

    def _pair_to_index(self, i: int, j: int) -> int:
        """将模型对索引转换为平面索引。"""
        if i > j:
            i, j = j, i
        return i * (self.n_models - 1) - (i * (i - 1)) // 2 + (j - i - 1)

    def _index_to_pair(self, idx: int) -> Tuple[int, int]:
        """将平面索引转换为模型对索引。"""
        i = 0
        while idx >= self.n_models - i - 1:
            idx -= self.n_models - i - 1
            i += 1
        j = i + idx + 1
        return i, j

    def fit_latency_parameters(self, completions_df: pd.DataFrame):
        """为每个模型的延迟分布拟合对数正态参数。"""
        self.latency_params = {}

        for model in self.models:
            model_latencies = completions_df[completions_df["model"] == model][
                "latency"
            ]
            model_latencies = model_latencies[np.isfinite(model_latencies)]

            if len(model_latencies) > 0:
                # 拟合对数正态分布
                shape, loc, scale = lognorm.fit(model_latencies, floc=0)
                # 转换为 mu 和 sigma 参数
                mu = np.log(scale)
                sigma = shape
                self.latency_params[model] = (mu, sigma)
            else:
                print(f"Warning: No latency data for model {model}")
                self.latency_params[model] = (0, 1)  # 默认参数

        print(self.latency_params)

    def compute_battle_statistics(self, outcomes_df: pd.DataFrame):
        """从结果数据中计算战斗次数和偏好。"""
        battle_counts = np.zeros((self.n_models, self.n_models))
        battle_preferences = np.zeros((self.n_models, self.n_models))

        for _, row in outcomes_df.iterrows():
            items = (
                json.loads(row["completionItems"])
                if isinstance(row["completionItems"], str)
                else row["completionItems"]
            )

            if len(items) < 2:
                continue

            # 仅考虑每场战斗中的前两个模型
            model1, model2 = items[0]["model"], items[1]["model"]
            if model1 not in self.model_to_idx or model2 not in self.model_to_idx:
                continue

            i, j = self.model_to_idx[model1], self.model_to_idx[model2]
            battle_counts[i, j] += 1
            battle_counts[j, i] += 1

            # 使用 acceptedIndex 确定偏好
            if row.get("acceptedIndex") == 0:
                battle_preferences[i, j] += 1
                battle_preferences[j, i] -= 1
            elif row.get("acceptedIndex") == 1:
                battle_preferences[i, j] -= 1
                battle_preferences[j, i] += 1

        self.battle_counts = battle_counts
        self.battle_preferences = battle_preferences

    def compute_latency_objective(self, probs: np.ndarray) -> float:
        """使用精确的PDF/CDF计算来计算期望的最大延迟目标。"""

        def max_latency_integrand(
            l: float, mu_i: float, sigma_i: float, mu_j: float, sigma_j: float
        ) -> float:
            """计算最大延迟的密度函数： f_max(l) = f(l;mu_i,sigma_i)F(l;mu_j,sigma_j) + F(l;mu_i,sigma_i)f(l;mu_j,sigma_j)"""
            # 模型 i 的概率密度函数 (PDF)
            f_i = lognorm.pdf(l, sigma_i, scale=np.exp(mu_i))
            # 模型 j 的累积分布函数 (CDF)
            F_j = lognorm.cdf(l, sigma_j, scale=np.exp(mu_j))
            # 模型 j 的概率密度函数 (PDF)
            f_j = lognorm.pdf(l, sigma_j, scale=np.exp(mu_j))
            # 模型 i 的 CDF
            F_i = lognorm.cdf(l, sigma_i, scale=np.exp(mu_i))

            max_latency = l * (f_i * F_j + F_i * f_j)
            return max_latency

        total_latency = 0
        max_expected_latency = 0
        expected_max_values = []
        
        # 首先计算所有对的期望延迟并找到最大值，用于归一化
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            mu_i, sigma_i = self.latency_params[self.models[i]]
            mu_j, sigma_j = self.latency_params[self.models[j]]

            # 将最大延迟密度函数从0积分到无穷大
            expected_max, _ = quad(
                max_latency_integrand, 0, np.inf, args=(mu_i, sigma_i, mu_j, sigma_j)
            )
            
            expected_max_values.append(expected_max)
            max_expected_latency = max(max_expected_latency, expected_max)
        
        # 使用最大值归一化并计算加权和
        for idx in range(self.n_pairs):
            # 归一化到0-1范围
            normalized_expected_max = expected_max_values[idx] / max_expected_latency if max_expected_latency > 0 else 0
            total_latency += probs[idx] * normalized_expected_max

        return total_latency

    def compute_rarity_objective(self, probs: np.ndarray) -> float:
        """计算稀有性目标。"""
        epsilon = 1.0  # 平滑因子
        rarity_scores = []
        total_rarity = 0
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            count = self.battle_counts[i, j]
            rarity_score = 1.0 / (count + epsilon)
            rarity_scores.append(rarity_score)
            total_rarity -= probs[idx] * rarity_score

        return total_rarity

    def compute_ambiguity_objective(self, probs: np.ndarray) -> float:
        """计算模糊目标。"""
        total_ambiguity = 0
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            if self.battle_counts[i, j] > 0:
                avg_preference = (
                    self.battle_preferences[i, j] / self.battle_counts[i, j]
                )
                ambiguity_score = 1.0 - abs(avg_preference)
                total_ambiguity -= probs[idx] * ambiguity_score
        return total_ambiguity

    def objective_function(self, theta: np.ndarray) -> float:
        """用于优化的组合目标函数。"""
        # 将 theta 转换为概率
        probs = np.exp(theta) / np.sum(np.exp(theta))

        # 计算单个目标
        latency_obj = self.compute_latency_objective(probs)
        rarity_obj = self.compute_rarity_objective(probs)
        ambiguity_obj = self.compute_ambiguity_objective(probs)

        # 用权重组合目标
        total_obj = (
            self.lambda_latency * latency_obj
            + self.lambda_rarity * rarity_obj
            + self.lambda_ambiguity * ambiguity_obj
        )

        return total_obj

    def fit(self, max_iter: int = 1000):
        """优化路由参数。"""
        # 创建一个更新进度条的包装函数
        pbar = tqdm(total=max_iter, desc="Optimizing routing parameters")
        iter_count = [0]  # 使用列表以允许在嵌套函数中进行修改

        def objective_with_progress(x):
            iter_count[0] += 1
            pbar.update(1)
            print(self._softmax_function(self.theta))
            return self.objective_function(x)

        try:
            result = minimize(
                objective_with_progress,
                self.theta,
                method="L-BFGS-B",
                options={"maxiter": max_iter},
            )
            self.theta = result.x
            return result
        finally:
            pbar.close()

    def get_routing_probabilities(self, temp=1.0) -> Dict[Tuple[str, str], float]:
        """获取每个模型对的优化路由概率。"""
        probs = self._softmax_function(theta=self.theta, temp=temp)
        routing_probs = {}

        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            model_i, model_j = self.models[i], self.models[j]
            routing_probs[(model_i, model_j)] = probs[idx]

        return routing_probs

    def sample_model_pair(self) -> Tuple[str, str]:
        """根据优化后的分布采样一个模型对。"""
        probs = self._softmax_function(theta=self.theta)
        idx = np.random.choice(self.n_pairs, p=probs)
        i, j = self._index_to_pair(idx)
        return self.models[i], self.models[j]

    def visualize_probability_matrix(self, temp=1.0):
        """为所有模型对创建并显示概率矩阵。"""
        import matplotlib.pyplot as plt
        import seaborn as sns

        # 初始化概率矩阵
        prob_matrix = np.zeros((self.n_models, self.n_models))

        # 获取概率
        probs = self._softmax_function(theta=self.theta, temp=temp)

        # 填充矩阵
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            prob = probs[idx]
            # 填充矩阵的两侧
            prob_matrix[i, j] = prob
            prob_matrix[j, i] = prob

        # 创建图形
        plt.figure(figsize=(15, 12))

        # 创建热图
        sns.heatmap(
            prob_matrix,
            xticklabels=self.models,
            yticklabels=self.models,
            annot=True,  # 在单元格中显示概率
            fmt=".3f",  # 将概率格式化为小数点后三位
            cmap="YlOrRd",
        )

        plt.title("Model Pairing Probabilities")
        plt.xticks(rotation=45, ha="right")
        plt.yticks(rotation=0)
        plt.tight_layout()

        # 如果需要，返回矩阵以进行进一步分析
        return prob_matrix

    def print_probability_matrix(self, temp=1.0):
        """打印概率矩阵为格式化表格。"""
        probs = self._softmax_function(theta=self.theta, temp=temp)
        prob_matrix = np.zeros((self.n_models, self.n_models))

        # 填充矩阵
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            prob = probs[idx]
            prob_matrix[i, j] = prob
            prob_matrix[j, i] = prob

        # 打印标题
        print("\nProbability Matrix:")
        print("-" * 120)
        print(f"{'Model':30}", end="")
        for model in self.models:
            print(f"{model:>10}", end="")
        print("\n" + "-" * 120)

        # 打印行
        for i, model1 in enumerate(self.models):
            print(f"{model1:30}", end="")
            for j, model2 in enumerate(self.models):
                if i == j:
                    print(f"{'---':>10}", end="")
                else:
                    print(f"{prob_matrix[i,j]:10.3f}", end="")
            print()

        print("-" * 120)

        return prob_matrix

    def calculate_expected_latency(self, temp: float = 1.0) -> float:
        """计算在当前路由概率下所有模型对的预期延迟。

参数:
    temp (float): 用于softmax概率计算的温度参数

返回:
    float: 预期延迟（以秒为单位）"""
        if not self.latency_params:
            raise ValueError(
                "Latency parameters not fitted. Call fit_latency_parameters first."
            )

        # 获取当前路由概率
        probs = self._softmax_function(theta=self.theta, temp=temp)

        total_expected_latency = 0

        # 对于每对模型
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            mu_i, sigma_i = self.latency_params[self.models[i]]
            mu_j, sigma_j = self.latency_params[self.models[j]]

            # 计算该对的期望最大延迟
            def max_latency_integrand(
                l: float, mu_i: float, sigma_i: float, mu_j: float, sigma_j: float
            ) -> float:
                f_i = lognorm.pdf(l, sigma_i, scale=np.exp(mu_i))
                F_j = lognorm.cdf(l, sigma_j, scale=np.exp(mu_j))
                f_j = lognorm.pdf(l, sigma_j, scale=np.exp(mu_j))
                F_i = lognorm.cdf(l, sigma_i, scale=np.exp(mu_i))
                return l * (f_i * F_j + F_i * f_j)

            # 对该对进行积分以获得期望的最大延迟
            pair_expected_latency, _ = quad(
                max_latency_integrand, 0, np.inf, args=(mu_i, sigma_i, mu_j, sigma_j)
            )

            # 按选择该对的概率加权
            total_expected_latency += probs[idx] * pair_expected_latency

        return total_expected_latency

    def print_expected_latencies(
        self, temperatures: List[float] = [1.0, 2.0, 5.0, 10.0]
    ):
        """打印不同温度值的预期延迟。

参数：
    temperatures (List[float]): 要评估的温度值列表"""
        print("\nExpected Latencies:")
        print("-" * 50)
        print(f"{'Temperature':>12} | {'Expected Latency (s)':>20}")
        print("-" * 50)

        for temp in temperatures:
            expected_latency = self.calculate_expected_latency(temp)
            print(f"{temp:12.1f} | {expected_latency:20.3f}")
        print("-" * 50)


# 示例用法
def main():
    models = [
        "gpt-4o-mini-2024-07-18",
        "codestral-2405",
        "llama-3.1-70b-instruct",
        "llama-3.1-405b-instruct",
        "gemini-1.5-flash-002",
        "gemini-1.5-pro-002",
        "claude-3-5-sonnet-20240620",
        "claude-3-5-sonnet-20241022",
        "qwen-2.5-coder-32b-instruct",
        "gpt-4o-2024-08-06",
    ]
    # 使用模型列表初始化路由器
    lambda_latency = 1
    lambda_rarity = 1
    lambda_ambiguity = 1
    router = ModelRouter(
        models,
        lambda_latency=lambda_latency,
        lambda_rarity=lambda_rarity,
        lambda_ambiguity=lambda_ambiguity,
    )

    # 从 csv 加载数据框
    global_completions_df = pd.read_csv("completions_data.csv")
    global_outcomes_df = pd.read_csv("outcomes_data.csv")

    # 拟合延迟参数
    router.fit_latency_parameters(global_completions_df)

    # 计算战斗统计数据
    router.compute_battle_statistics(global_outcomes_df)

    filename = "routing_parameters_{}_{}_{}.json".format(
        lambda_latency, lambda_rarity, lambda_ambiguity
    )
    # 如果 routing_parameters 存在则加载它
    try:
        with open(filename, "r") as f:
            routing_parameters = json.load(f)
            router.theta = np.array(routing_parameters["theta"])
    except FileNotFoundError:
        # 优化路由参数
        result = router.fit()
        print("Optimization completed:", result.success)

    # 保存结果
    with open(filename, "w") as f:
        json.dump({"theta": router.theta.tolist()}, f)

    # 探索不同温度下的路由概率
    temperatures = [1.0, 2.0, 5.0, 10.0, 100.0, 1000.0]
    for temp in temperatures:
        routing_probs = router.get_routing_probabilities(temp=temp)
        sorted_pairs = sorted(routing_probs.items(), key=lambda x: x[1], reverse=True)

        print(f"Top 10 model pairs by routing probability (temperature={temp:.1f}):")
        for (model1, model2), prob in sorted_pairs[:10]:
            print(f"{model1} vs {model2}: {prob:.4f}")

        # 打印文本版本
        router.print_probability_matrix(temp=temp)

        # 显示可视化热图
        # router.可视化概率矩阵(temp=temp)
        # plt.title(f"模型配对概率（温度 = {temp:.1f}）")
        # plt.show()

    router.print_expected_latencies(temperatures)


if __name__ == "__main__":
    main()