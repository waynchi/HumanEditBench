from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# 创建一个Spark会话
spark = SparkSession.builder.appName("EscrituraParquetADL2").getOrCreate()

# 示例数据（用你的真实数据替换）
data = [
    {"id": 1, "nombre": "Juan", "edad": 30},
    {"id": 2, "nombre": "Ana", "edad": 25},
    {"id": 3, "nombre": "Pedro", "edad": 40}
]

# 从数据创建一个DataFrame
df = spark.createDataFrame(data)

# 分析数据结构和内容
print("DataFrame Schema:")
df.printSchema()

print("\nDataFrame Summary Statistics:")
df.describe().show()

print("\nSample Data:")
df.show(5)

print("\nColumn Names:")
print(df.columns)

print("\nRow Count:")
print(df.count())

# 可以进一步探索数据中的特定列
print("\nUnique Values in 'nombre' column:")
df.select("nombre").distinct().show()

# 配置与ADL2的连接使用Microsoft ID身份
# 在Synapse的笔记本中不需要显式提供凭据
# Spark将使用notebook的托管身份进行身份验证。

# 指定ADL2中容器和文件夹的路径
container_name = "<your_container_name>"  # 用你的容器名称替换
folder_path = "<your_folder_path>"  # 替换为容器内文件夹的路径
adl2_path = f"abfss://{container_name}@{<your_storage_account_name>}.dfs.core.windows.net/{folder_path}"

# 将DataFrame以parquet格式写入ADL2
df.write.parquet(adl2_path, mode="overwrite")

# 可选：读取parquet文件进行验证
df_leido = spark.read.parquet(adl2_path)
df_leido.show()

# 停止 Spark 会话
spark.stop()