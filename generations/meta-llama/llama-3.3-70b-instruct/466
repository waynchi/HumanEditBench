from langchain import LLMChain, PromptTemplate
from langchain.llms import LLaMA

llm = LLaMA(model_size="3.2")

template = PromptTemplate(
    input_variables=["sys_prompt", "shap_values_json"],
    template="{sys_prompt}\n{shap_values_json}",
)

with open("Vuori_Final_Approval_2024_09_24.json", "r") as file:
    shap_values_json = json.load(file).get("shap_values")
with open("system.prompt", "r") as file:
    sys_prompt = file.read().strip()

chain = LLMChain(
    llm=llm, 
    prompt=template, 
    input_variables={"sys_prompt": sys_prompt, "shap_values_json": str(shap_values_json)}
)

response = chain({"sys_prompt": sys_prompt, "shap_values_json": str(shap_values_json)})

print(response)
