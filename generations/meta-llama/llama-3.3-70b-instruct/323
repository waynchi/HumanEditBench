from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
import httpx
import asyncio
import json
import logging
import random
from typing import List, Dict

app = FastAPI()

CHAT_URL = "https://duckduckgo.com/duckchat/v1/chat"
STATUS_URL = "https://duckduckgo.com/duckchat/v1/status"
MODELS = {
    "gpt-4o-mini": {"owned_by": "openai", "is_free": True},
    "llama-3.1-70b": {"owned_by": "Meta", "is_free": True},
    "mixtral-8x7b": {"owned_by": "mistralai", "is_free": True},
    "claude-3-haiku": {"owned_by": "Anthropic", "is_free": False},
}

USER_AGENT_TABLE = [
    # Windows
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.3",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36",
    # Mac
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_3_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.3",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_3_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.4 Safari/605.1.15",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 12_6_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36",
    # Linux
    "Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0",
]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def fetch_vqd() -> dict:
    """Fetch the VQD token required for authentication."""
    user_agent = random.choice(USER_AGENT_TABLE)
    async with httpx.AsyncClient() as client:
        response = await client.get(
            STATUS_URL,
            headers={
                "User-Agent": user_agent,
                "x-vqd-accept": "1",
            },
        )
        if response.status_code != 200:
            logger.error(f"Failed to fetch VQD: {response.status_code}")
            raise HTTPException(status_code=500, detail="Failed to retrieve VQD token")
        return {
            "vqd": response.headers.get("x-vqd-4", ""),
            "user-agent": user_agent
        }

async def stream_chat_response(client, vqd: str, messages: List[Dict], model: str, user_agent: str):
    """Передача ответа от API чата."""
    headers = {
        "User-Agent": user_agent,
        "Content-Type": "application/json",
        "x-vqd-4": vqd,
    }
    payload = {"model": model, "messages": messages}

    async with client.stream("POST", CHAT_URL, headers=headers, json=payload) as response:
        if response.status_code != 200:
            logger.error(f"Chat request failed: {response.status_code}")
            raise HTTPException(status_code=response.status_code, detail="Chat API request failed")
        async for line in response.aiter_lines():
            yield line

# Сохранить VQD токены с их заголовками авторизации
vqd_cache = {}
@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """Обработка завершений чата с опциональной потоковой передачей."""
    try:
        data = await request.json()
        messages = data.get("messages", [])
        model = data.get("model", "gpt-4o-mini")
        stream = data.get("stream", False)

        if model not in MODELS:
            raise HTTPException(status_code=400, detail="Invalid model requested")

        # Получить заголовок авторизации
        auth_header = request.headers.get("authorization")
        
        # Проверяем, есть ли у нас закэшированный VQD для этого заголовка авторизации
        if auth_header not in vqd_cache:
            vqd_cache[auth_header] = await fetch_vqd()
        
        vqd_data = vqd_cache[auth_header]
        vqd = vqd_data["vqd"]
        user_agent = vqd_data["user-agent"]

        async with httpx.AsyncClient() as client:
            if stream:
                return StreamingResponse(
                    stream_chat_response(client, vqd, messages, model, user_agent),
                    media_type="text/event-stream",
                )
            else:
                aggregated_response = ""
                async for chunk in stream_chat_response(client, vqd, messages, model, user_agent):
                    aggregated_response += chunk
                return JSONResponse(content=json.loads(aggregated_response))
    except Exception as e:
        logger.error(f"Error in chat_completions: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@app.get("/v1/models")
async def get_models():
    """Получить доступные модели."""
    try:
        response_data = []
        for model_id, details in MODELS.items():
            response_data.append({
                "id": model_id,
                "object": "model",
                "created": 1686935002,  # Захардкожено для примера
                "owned_by": details["owned_by"],
                "type": "chat.completions",
                "is_free": details["is_free"],
            })
        return JSONResponse(content={"object": "list", "data": response_data})
    except Exception as e:
        logger.error(f"Error in get_models: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

# Точка входа для сервера разработки
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)