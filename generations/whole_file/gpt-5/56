import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import skew

# def medcouple(data):
#     data = np.sort(data)  # Сортируем данные
#     n = len(data)
#     median = np.median(data)

#     # Разделяем данные на меньше медианы и больше медианы
#     left = data[data <= median]
#     right = data[data >= median]

#     # Функция ядра h(xi, xj)
#     def h(xi, xj):
#         if xi != xj:
#             return ((xj - median) - (median - xi)) / (xj - xi)
#         return 0  # Хотя xi != xj должно исключать этот случай

#     # Специальное ядро для случаев с повторениями медианы
#     def special_h(i, j, k):
#         if i + j - 1 < k:
#             return -1
#         elif i + j - 1 == k:
#             return 0
#         elif i + j - 1 > k:
#             return 1

#     # Генерация всех возможных h(xi, xj)
#     h_values = []
#     k = len(data[data == median])  # Количество повторяющихся значений медианы
#     if k > 1:  # Обработка случая с совпадающими медианами
#         for i, xi in enumerate(left):
#             for j, xj in enumerate(right):
#                 if xi == xj == median:
#                     h_values.append(special_h(i, j, k))
#                 else:
#                     h_values.append(h(xi, xj))
#     else:
#         for xi in left:
#             for xj in right:
#                 h_values.append(h(xi, xj))

#     # Возвращаем медиану всех значений h
#     return np.median(h_values)
# Нужно ускорить и переписать функцию medcouple 

def medcouple(data):
    data = np.asarray(data, dtype=float)
    data = np.sort(data)
    median = np.median(data)

    # Split data into left and right of the median
    left = data[data <= median]
    right = data[data >= median]

    L = left.size
    R = right.size

    # Prepare broadcasted grids
    Xi = left.reshape(L, 1)
    Xj = right.reshape(1, R)

    # Denominator and numerator for kernel h
    D = Xj - Xi
    numerator = (Xj + Xi - 2.0 * median)

    # Initialize H matrix
    H = np.empty((L, R), dtype=float)

    # Compute where denominator is non-zero
    nz = D != 0
    H[nz] = numerator[nz] / D[nz]

    # Handle ties where Xi == Xj == median (D == 0)
    z = ~nz
    if np.any(z):
        k = np.count_nonzero(data == median)  # number of repeated medians
        I = np.arange(L).reshape(L, 1)
        J = np.arange(R).reshape(1, R)
        S = I + J - 1
        # Vectorized special_h: -1 if S<k, 0 if S==k, else 1
        special_vals = np.where(S < k, -1.0, np.where(S == k, 0.0, 1.0))
        H[z] = special_vals[z]

    # Median of all kernel values
    return float(np.median(H))

def adjusted_boxplot_bounds(data):
    """
    Вычисляет границы adjusted boxplot с учетом skewness-adjusted fences.
    """
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    iqr = q3 - q1
    _medcouple = medcouple(data)

    if _medcouple > 0:
        lower_fence = q1 - 1.5 * np.exp(-4 * _medcouple) * iqr
        upper_fence = q3 + 1.5 * np.exp(3 * _medcouple) * iqr
    else:
        lower_fence = q1 - 1.5 * np.exp(-3 * _medcouple) * iqr
        upper_fence = q3 + 1.5 * np.exp(4 * _medcouple) * iqr

    return lower_fence, upper_fence

def normalize_column(data):
    """
    Нормализация с использованием adjusted boxplot.
    """
    lower_fence, upper_fence = adjusted_boxplot_bounds(data)
    print(lower_fence)
    return (data - lower_fence) / (upper_fence - lower_fence)

# Генерация данных
np.random.seed(42)
data_normal = np.random.normal(loc=50, scale=10, size=10000)
data_skewed = np.random.exponential(scale=20, size=10000)
data_skewed = np.concatenate([data_skewed[5:], [200, 250, 300, -100, -50]])
data_with_outliers = np.concatenate([data_normal, [150, 160, 170]])

# Нормализация
df = pd.DataFrame({
    "Normal": data_normal,
    "Skewed": data_skewed,
    # "With_Outliers": data_with_outliers[3:],
})

normalized_df = df.apply(normalize_column)

plt.figure(figsize=(16, 4), dpi=250)

bins = np.linspace(-5, 200, 206)
bin_width = bins[1] - bins[0]  # Ширина одного бина

for col in df.columns:
    # plt.hist(df[col], bins=50, alpha=0.5, label=f'{col} - Original')
    # Вычисляем гистограммы без построения
    hist, _ = np.histogram(df[col], bins=bins)

    # Позиции столбиков для каждой гистограммы
    bin_centers = (bins[:-1] + bins[1:]) / 2

    # Смещение для каждого набора данных
    offset = bin_width / 4
    plt.bar(bin_centers - offset, hist, width=bin_width, align='center', alpha=0.2, label=f'{col}')
    plt.legend()
    plt.title(f"Histogram Before Normalization")
plt.xlim(-10, 200)
plt.show()

bins = np.linspace(-2, 2, 101)
bin_width = bins[1] - bins[0]  # Ширина одного бина


plt.figure(figsize=(16, 4), dpi=250)
for col in normalized_df.columns:
    # plt.hist(normalized_df[col], bins=50, alpha=0.5, label=f'{col} - Normalized')
    hist, _ = np.histogram(normalized_df[col], bins=bins)

    # Позиции столбиков для каждой гистограммы
    bin_centers = (bins[:-1] + bins[1:]) / 2
    # Смещение для каждого набора данных
    offset = bin_width / 2
    plt.bar(bin_centers - offset, hist, width=bin_width, align='center', label=f'{col}', alpha=0.2)
    plt.legend()
    plt.title(f"Histogram After Normalization")
plt.show()