import numpy as np
from matplotlib import pyplot as plt
from scipy.stats import lognorm
from scipy.optimize import minimize
from scipy.integrate import quad
import pandas as pd
from tqdm import tqdm
from typing import Dict, List, Tuple
import json
import pandas as pd


class ModelRouter:
    def __init__(
        self,
        models: List[str],
        lambda_latency: float = 1.0,
        lambda_rarity: float = 1.0,
        lambda_ambiguity: float = 1.0,
    ):
        self.models = models
        self.n_models = len(models)
        self.model_to_idx = {model: idx for idx, model in enumerate(models)}
        self.lambda_latency = lambda_latency
        self.lambda_rarity = lambda_rarity
        self.lambda_ambiguity = lambda_ambiguity

        # 初始化参数
        self.n_pairs = (self.n_models * (self.n_models - 1)) // 2
        self.theta = np.zeros(self.n_pairs)

        # 战斗统计的缓存
        self.battle_counts = None
        self.battle_preferences = None

        # 延迟参数的缓存
        self.latency_params = None

    def _softmax_function(self, theta: np.ndarray, temp: float = 1.0) -> np.ndarray:
        """使用带温度的softmax将参数转换为概率。"""
        exp_theta = np.exp(theta / temp)
        return exp_theta / np.sum(exp_theta)

    def _pair_to_index(self, i: int, j: int) -> int:
        """将模型对索引转换为平面索引。"""
        if i > j:
            i, j = j, i
        return i * (self.n_models - 1) - (i * (i - 1)) // 2 + (j - i - 1)

    def _index_to_pair(self, idx: int) -> Tuple[int, int]:
        """将平面索引转换为模型对索引。"""
        i = 0
        while idx >= self.n_models - i - 1:
            idx -= self.n_models - i - 1
            i += 1
        j = i + idx + 1
        return i, j

    def fit_latency_parameters(self, completions_df: pd.DataFrame):
        """为每个模型的延迟分布拟合对数正态参数。"""
        self.latency_params = {}

        for model in self.models:
            model_latencies = completions_df[completions_df["model"] == model][
                "latency"
            ]
            model_latencies = model_latencies[np.isfinite(model_latencies)]

            if len(model_latencies) > 0:
                # 拟合对数正态分布
                shape, loc, scale = lognorm.fit(model_latencies, floc=0)
                # 转换为 mu 和 sigma 参数
                mu = np.log(scale)
                sigma = shape
                self.latency_params[model] = (mu, sigma)
            else:
                print(f"Warning: No latency data for model {model}")
                self.latency_params[model] = (0, 1)  # 默认参数

        print(self.latency_params)

    def compute_battle_statistics(self, outcomes_df: pd.DataFrame):
        """从结果数据中计算战斗次数和偏好。"""
        battle_counts = np.zeros((self.n_models, self.n_models))
        battle_preferences = np.zeros((self.n_models, self.n_models))

        for _, row in outcomes_df.iterrows():
            items = (
                json.loads(row["completionItems"])
                if isinstance(row["completionItems"], str)
                else row["completionItems"]
            )

            if len(items) < 2:
                continue

            # 只考虑每场战斗中的前两个模型
            model1, model2 = items[0]["model"], items[1]["model"]
            if model1 not in self.model_to_idx or model2 not in self.model_to_idx:
                continue

            i, j = self.model_to_idx[model1], self.model_to_idx[model2]
            battle_counts[i, j] += 1
            battle_counts[j, i] += 1

            # 使用 acceptedIndex 确定偏好
            if row.get("acceptedIndex") == 0:
                battle_preferences[i, j] += 1
                battle_preferences[j, i] -= 1
            elif row.get("acceptedIndex") == 1:
                battle_preferences[i, j] -= 1
                battle_preferences[j, i] += 1

        self.battle_counts = battle_counts
        self.battle_preferences = battle_preferences

    def compute_latency(self):
        """使用精确的PDF/CDF计算来计算预期的最大延迟目标。"""

        def max_latency_integrand(
            l: float, mu_i: float, sigma_i: float, mu_j: float, sigma_j: float
        ) -> float:
            """计算最大延迟的密度函数： f_max(l) = f(l;mu_i,sigma_i)F(l;mu_j,sigma_j) + F(l;mu_i,sigma_i)f(l;mu_j,sigma_j)"""
            # 模型 i 的概率密度函数 (PDF)
            f_i = lognorm.pdf(l, sigma_i, scale=np.exp(mu_i))
            # 模型 j 的累积分布函数 (CDF)
            F_j = lognorm.cdf(l, sigma_j, scale=np.exp(mu_j))
            # 模型 j 的概率密度函数 (PDF)
            f_j = lognorm.pdf(l, sigma_j, scale=np.exp(mu_j))
            # 模型 i 的 CDF
            F_i = lognorm.cdf(l, sigma_i, scale=np.exp(mu_i))

            max_latency = l * (f_i * F_j + F_i * f_j)
            return max_latency

        total_latency = 0
        self.latencies = []

        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            mu_i, sigma_i = self.latency_params[self.models[i]]
            mu_j, sigma_j = self.latency_params[self.models[j]]

            # 将最大延迟密度函数从0积分到无穷大
            expected_max, _ = quad(
                max_latency_integrand, 0, np.inf, args=(mu_i, sigma_i, mu_j, sigma_j)
            )

            self.latencies.append(expected_max)

        self.latencies = np.array(self.latencies)

        self.normalized_latencies = (self.latencies - min(self.latencies)) / (
            max(self.latencies) - min(self.latencies)
        )

    def compute_latency_objective(self, probs: np.ndarray) -> float:

        total_normalized_latency = sum(
            [probs[idx] * self.normalized_latencies[idx] for idx in range(self.n_pairs)]
        )

        return total_normalized_latency

    def compute_rarity_objective(self, probs: np.ndarray) -> float:
        """计算稀有性目标。"""
        epsilon = 1.0  # 平滑因子
        rarity_scores = []
        total_rarity = 0
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            count = self.battle_counts[i, j]
            rarity_score = 1.0 / (count + epsilon)
            rarity_scores.append(rarity_score)
            total_rarity -= probs[idx] * rarity_score

        return total_rarity

    def compute_ambiguity_objective(self, probs: np.ndarray) -> float:
        """计算模糊目标。"""
        total_ambiguity = 0
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            if self.battle_counts[i, j] > 0:
                avg_preference = (
                    self.battle_preferences[i, j] / self.battle_counts[i, j]
                )
                ambiguity_score = 1.0 - abs(avg_preference)
                total_ambiguity -= probs[idx] * ambiguity_score
        return total_ambiguity

    def objective_function(self, theta: np.ndarray) -> float:
        """用于优化的组合目标函数。"""
        # 将 theta 转换为概率
        probs = np.exp(theta) / np.sum(np.exp(theta))

        # 计算单个目标
        latency_obj = self.compute_latency_objective(probs)
        rarity_obj = self.compute_rarity_objective(probs)
        ambiguity_obj = self.compute_ambiguity_objective(probs)

        # 用权重组合目标
        total_obj = (
            self.lambda_latency * latency_obj
            + self.lambda_rarity * rarity_obj
            + self.lambda_ambiguity * ambiguity_obj
        )

        return total_obj

    def fit(self, max_iter: int = 1000):
        """优化路由参数。"""
        # 创建一个更新进度条的包装函数
        pbar = tqdm(total=max_iter, desc="Optimizing routing parameters")
        iter_count = [0]  # 使用列表以允许在嵌套函数中进行修改

        def objective_with_progress(x):
            iter_count[0] += 1
            pbar.update(1)
            print(self._softmax_function(self.theta))
            return self.objective_function(x)

        try:
            result = minimize(
                objective_with_progress,
                self.theta,
                method="L-BFGS-B",
                options={"maxiter": max_iter},
            )
            self.theta = result.x
            return result
        finally:
            pbar.close()

    def get_routing_probabilities(self, temp=1.0) -> Dict[Tuple[str, str], float]:
        """获取每个模型对的优化路由概率。"""
        probs = self._softmax_function(theta=self.theta, temp=temp)
        routing_probs = {}

        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            model_i, model_j = self.models[i], self.models[j]
            routing_probs[(model_i, model_j)] = probs[idx]

        return routing_probs

    def sample_model_pair(self) -> Tuple[str, str]:
        """根据优化后的分布采样一个模型对。"""
        probs = self._softmax_function(theta=self.theta)
        idx = np.random.choice(self.n_pairs, p=probs)
        i, j = self._index_to_pair(idx)
        return self.models[i], self.models[j]

    def visualize_probability_matrix(self, temp=1.0):
        """为所有模型对创建并显示概率矩阵。"""
        import matplotlib.pyplot as plt
        import seaborn as sns

        # 初始化概率矩阵
        prob_matrix = np.zeros((self.n_models, self.n_models))

        # 获取概率
        probs = self._softmax_function(theta=self.theta, temp=temp)

        # 填充矩阵
        for idx in range(self.n_pairs):
            i, j = self._index_to_pair(idx)
            prob = probs[idx]
            # 填充矩阵的两侧
            prob_matrix[i, j] = prob
            prob_matrix[j, i] = prob

        # 创建图形
        plt.figure(figsize=(15, 12))

        # 创建热图
        sns.heatmap(
            prob_matrix,
            xticklabels=self.models,
            yticklabels=self.models,
            annot=True,  # 在单元格中显示概率
            fmt=".3f",  # 将概率格式化为小数点后三位
            cmap="YlOrRd",
        )

        plt.title("Model Pairing Probabilities")
        plt.xticks(rotation=45, ha="right")
        plt.yticks(rotation=0)
        plt.tight_layout()

        # 如有需要，返回矩阵以供进一步分析
        return prob_matrix

    def print_probability_matrix(self, temp=1.0, title=""):
        """打印概率矩阵为格式化表格。"""
        with open("probability_matrix_output.txt", "a", encoding="utf-8") as f:
            f.write(title + "\n")
            probs = self._softmax_function(theta=self.theta, temp=temp)
            prob_matrix = np.zeros((self.n_models, self.n_models))

            # 填充矩阵
            for idx in range(self.n_pairs):
                i, j = self._index_to_pair(idx)
                prob = probs[idx]
                prob_matrix[i, j] = prob
                prob_matrix[j, i] = prob

            # 打印标题
            f.write("\nProbability Matrix:\n")
            f.write("-" * 120 + "\n")
            f.write(f"{'Model':30}")
            for model in self.models:
                f.write(f"{model:>10}")
            f.write("\n" + "-" * 120 + "\n")

            # 打印行
            for i, model1 in enumerate(self.models):
                f.write(f"{model1:30}")
                for j, model2 in enumerate(self.models):
                    if i == j:
                        f.write(f"{'---':>10}")
                    else:
                        f.write(f"{prob_matrix[i,j]:10.3f}")
                f.write("\n")

            f.write("-" * 120 + "\n")

        return prob_matrix

    def calculate_expected_latency(self, temp: float = 1.0) -> float:
        """计算在给定当前路由概率的情况下，所有模型对的预期延迟。

参数:
    temp (float): 用于softmax概率计算的温度参数

返回:
    float: 预期延迟（以秒为单位）"""
        if not self.latency_params:
            raise ValueError(
                "Latency parameters not fitted. Call fit_latency_parameters first."
            )

        # 获取当前路由概率
        probs = self._softmax_function(theta=self.theta, temp=temp)
        total_expected_latency = sum(
            [probs[idx] * self.latencies[idx] for idx in range(self.n_pairs)]
        )

        return total_expected_latency

    def print_expected_latencies(
        self, temperatures: List[float] = [1.0, 2.0, 5.0, 10.0]
    ):
        """打印不同温度值的预期延迟。

参数：
    temperatures (List[float]): 要评估的温度值列表"""
        print("\nExpected Latencies:")
        print("-" * 50)
        print(f"{'Temperature':>12} | {'Expected Latency (s)':>20}")
        print("-" * 50)

        for temp in temperatures:
            expected_latency = self.calculate_expected_latency(temp)
            print(f"{temp:12.1f} | {expected_latency:20.3f}")
        print("-" * 50)


# 示例用法
def main():
    models = [
        "gpt-4o-mini-2024-07-18",
        "codestral-2405",
        "llama-3.1-70b-instruct",
        "llama-3.1-405b-instruct",
        "gemini-1.5-flash-002",
        "gemini-1.5-pro-002",
        "claude-3-5-sonnet-20240620",
        "claude-3-5-sonnet-20241022",
        "qwen-2.5-coder-32b-instruct",
        "gpt-4o-2024-08-06",
    ]
    # 使用模型列表初始化路由器
    lambda_latency = 0.1
    lambda_rarity = 1
    lambda_ambiguity = 1
    router = ModelRouter(
        models,
        lambda_latency=lambda_latency,
        lambda_rarity=lambda_rarity,
        lambda_ambiguity=lambda_ambiguity,
    )

    # 从 csv 加载数据框
    global_completions_df = pd.read_csv("completions_data.csv")
    global_outcomes_df = pd.read_csv("outcomes_data.csv")

    # 拟合延迟参数
    router.fit_latency_parameters(global_completions_df)
    router.compute_latency()
    # 计算战斗统计数据
    router.compute_battle_statistics(global_outcomes_df)

    # 为 lambda 参数扫描定义范围
    lambda_latency_values = np.arange(0, 1, 0.1)
    lambda_rarity_values = np.arange(0, 1, 0.1)
    lambda_ambiguity_values = np.arange(0, 1, 0.1)

    # 遍历所有 lambda 值的组合
    for lambda_latency in lambda_latency_values:
        for lambda_rarity in lambda_rarity_values:
            for lambda_ambiguity in lambda_ambiguity_values:
                # 更新路由器的 lambda 值
                router.lambda_latency = lambda_latency
                router.lambda_rarity = lambda_rarity
                router.lambda_ambiguity = lambda_ambiguity

                filename = "routing_params/routing_parameters_{}_{}_{}.json".format(
                    lambda_latency, lambda_rarity, lambda_ambiguity
                )

                # 如果存在则加载 routing_parameters
                try:
                    with open(filename, "r") as f:
                        routing_parameters = json.load(f)
                        router.theta = np.array(routing_parameters["theta"])
                except FileNotFoundError:
                    # 优化路由参数
                    result = router.fit()
                    print(f"Optimization completed for lambda values ({lambda_latency}, {lambda_rarity}, {lambda_ambiguity}): {result.success}")
                # 保存结果
                with open(filename, "w") as f:
                    json.dump({"theta": router.theta.tolist()}, f)

                # 探索不同温度下的路由概率
                temperatures = [1.0]
                for temp in temperatures:
                    routing_probs = router.get_routing_probabilities(temp=temp)
                    sorted_pairs = sorted(
                        routing_probs.items(), key=lambda x: x[1], reverse=True
                    )

                    # out_f.write(
                    # f"按路由概率排序的前10个模型对（温度={temp:.1f}）:
                    # )
                    # “对于 (model1, model2), prob 在 sorted_pairs[:10] 中”
                    # out_f.write(f"{model1} vs {model2}: {prob:.4f}")

                    # 打印文本版本
                    router.print_probability_matrix(temp=temp)

                router.print_expected_latencies(temperatures)


if __name__ == "__main__":
    main()