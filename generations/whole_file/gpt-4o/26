import numpy as np

def conjugate_gradient(A, b, x=None, tol=1e-10, max_iter=None):
    if x is None:
        x = np.zeros_like(b)
    
    r = b - A @ x
    p = r.copy()
    rs_old = np.dot(r, r)
    
    if max_iter is None:
        max_iter = 2 * len(b)
    
    for i in range(max_iter):
        Ap = A @ p
        alpha = rs_old / np.dot(p, Ap)
        x += alpha * p
        r -= alpha * Ap
        rs_new = np.dot(r, r)
        
        if np.sqrt(rs_new) < tol:
            break
        
        p = r + (rs_new / rs_old) * p
        rs_old = rs_new
        
    return x