from langchain_ollama.chat_models import ChatOllama

import json

from langchain import LLMChain, PromptTemplate
from langchain.llms import Ollama

# Initialize the Ollama model
llm = Ollama(model="llama3.2", host="http://localhost:11434")

# Load the SHAP values from the JSON file
with open("Vuori_Final_Approval_2024_09_24.json", "r") as file:
    shap_values_json = json.load(file).get("shap_values")

# Load the system prompt from the file
with open("system.prompt", "r") as file:
    sys_prompt = file.read().strip()

# Create the user prompt
prompt = f"""
{shap_values_json}
"""

# Create a prompt template
prompt_template = PromptTemplate(
    input_variables=["system_prompt", "user_prompt"],
    template="{system_prompt}\n\n{user_prompt}"
)

# Create the LLMChain
llm_chain = LLMChain(llm=llm, prompt=prompt_template)

# Generate the response
response = llm_chain.run(system_prompt=sys_prompt, user_prompt=prompt)

# Print the response
print(response)