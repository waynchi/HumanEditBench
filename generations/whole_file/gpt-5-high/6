# env: pyAI

import os
from openai import OpenAI
import json

def save_conversation(filename="conversation_history.json"):
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(conversation_history, f, ensure_ascii=False, indent=4)
        print(f"Conversation saved to {filename}.")
    except Exception as e:
        print(f"Failed to save conversation: {e}")


def load_conversation(filename="conversation_history.json"):
    try:
        with open(filename, "r", encoding="utf-8") as f:
            history = json.load(f)
        print(f"Conversation history from {filename} loaded successfully.")
        return history
    except FileNotFoundError:
        print(f"No saved conversation history found for {filename}.")
        return None
    except json.JSONDecodeError as e:
        print(f"Failed to parse {filename}: {e}")
        return None


# token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
model_name = "gpt-4o"

client = OpenAI(
    base_url=endpoint,
    api_key="XXXXXXXXXXXXXXXXXXXXXXXXXXXX",
)

# Ask the user if they want to load a conversation history
load_history = input("Do you want to load a conversation history? (yes/no): ").strip().lower()
conversation_history = []

def init_new_history():
    return [
        {
            "role": "system",
            "content": "You are a helpful assistant.",
        }
    ]

if load_history == "yes":
    # Get all conversation history files in the current directory
    history_files = [f for f in os.listdir() if f.endswith(".json")]
    if history_files:
        print("Available conversation history files:")
        for i, file in enumerate(history_files, 1):
            print(f"{i}. {file}")
        choice = input("Enter the number of the conversation history file to load: ").strip()
        try:
            choice_idx = int(choice)
            if 1 <= choice_idx <= len(history_files):
                history_file = history_files[choice_idx - 1]
                loaded_history = load_conversation(history_file)
                if loaded_history is not None and isinstance(loaded_history, list):
                    conversation_history = loaded_history
                else:
                    print("Loaded file is empty or invalid. Initializing new conversation history.")
                    conversation_history = init_new_history()
            else:
                print("Invalid choice. Initializing new conversation history.")
                conversation_history = init_new_history()
        except ValueError:
            print("Invalid input. Initializing new conversation history.")
            conversation_history = init_new_history()
    else:
        print("No conversation history files found. Initializing new conversation history.")
        conversation_history = init_new_history()
else:
    # 初始化对话历史
    conversation_history = init_new_history()

# 模拟连续对话
while True:
    user_input = input("User: ")
    if user_input.strip().lower() in ["exit", "quit"]:
        print("Exiting the conversation.")
        break

    conversation_history.append({
        "role": "user",
        "content": user_input
    })

    try:
        response = client.chat.completions.create(
            messages=conversation_history,
            temperature=1.0,
            top_p=1.0,
            max_tokens=4086,
            model=model_name
        )
    except Exception as e:
        print(f"Request failed: {e}")
        continue

    assistant_message = response.choices[0].message
    # Ensure the assistant message is stored as a serializable dict
    conversation_history.append({
        "role": getattr(assistant_message, "role", "assistant"),
        "content": getattr(assistant_message, "content", "")
    })
    print("GPT: ", getattr(assistant_message, "content", ""))

# Save the conversation history at the end
save_conversation()