import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import skew

# def medcouple(data):
#     data = np.sort(data)  # Сортируем данные
#     n = len(data)
#     median = np.median(data)
#
#     # Разделяем данные на меньше медианы и больше медианы
#     left = data[data <= median]
#     right = data[data >= median]
#
#     # Функция ядра h(xi, xj)
#     def h(xi, xj):
#         if xi != xj:
#             return ((xj - median) - (median - xi)) / (xj - xi)
#         return 0  # Хотя xi != xj должно исключать этот случай
#
#     # Специальное ядро для случаев с повторениями медианы
#     def special_h(i, j, k):
#         if i + j - 1 < k:
#             return -1
#         elif i + j - 1 == k:
#             return 0
#         elif i + j - 1 > k:
#             return 1
#
#     # Генерация всех возможных h(xi, xj)
#     h_values = []
#     k = len(data[data == median])  # Количество повторяющихся значений медианы
#     if k > 1:  # Обработка случая с совпадающими медианами
#         for i, xi in enumerate(left):
#             for j, xj in enumerate(right):
#                 if xi == xj == median:
#                     h_values.append(special_h(i, j, k))
#                 else:
#                     h_values.append(h(xi, xj))
#     else:
#         for xi in left:
#             for xj in right:
#                 h_values.append(h(xi, xj))
#
#     # Возвращаем медиану всех значений h
#     return np.median(h_values)
# Нужно ускорить и переписать функцию medcouple 

def medcouple(data):
    data = np.sort(data)
    n = len(data)
    median = np.median(data)

    # Split data into left and right of the median
    left = data[data <= median]
    right = data[data >= median]

    # Vectorized kernel function h(xi, xj)
    def h_vec(xi, xj):
        xi = np.asarray(xi, dtype=float)
        xj = np.asarray(xj, dtype=float)
        res = np.zeros_like(xi, dtype=float)
        neq = xj != xi
        # Compute only where denominator non-zero
        res[neq] = ((xj[neq] - median) - (median - xi[neq])) / (xj[neq] - xi[neq])
        return res

    # Vectorized special_h for repeated medians using array arithmetic
    def special_h_array(i_arr, j_arr, k):
        ij = i_arr + j_arr - 1
        # elementwise selection: -1 if <k, 0 if ==k, 1 if >k
        return np.where(ij < k, -1.0, np.where(ij == k, 0.0, 1.0))

    # Generate all possible h(xi, xj) using meshgrid and vectorized operations
    k = len(data[data == median])  # Count of repeated median values

    # If either side is empty, return 0 as a sane default (no pairs)
    if len(left) == 0 or len(right) == 0:
        return 0.0

    xi, xj = np.meshgrid(left, right, indexing='ij')  # shapes: (len(left), len(right))

    if k > 1:
        # indices for special_h logic (enumerate starts at 0 in original code)
        left_indices = np.arange(len(left))
        right_indices = np.arange(len(right))
        i_idx, j_idx = np.meshgrid(left_indices, right_indices, indexing='ij')
        # Compute base h values
        h_matrix = h_vec(xi, xj)
        # Mask where both xi and xj equal the median -> need special handling
        mask_med = (xi == median) & (xj == median)
        if np.any(mask_med):
            special_vals = special_h_array(i_idx, j_idx, k)
            # Assign special values only where mask_med is True
            h_matrix[mask_med] = special_vals[mask_med]
    else:
        h_matrix = h_vec(xi, xj)

    # Flatten the matrix and calculate the median of h values
    return np.median(h_matrix.flatten())

def adjusted_boxplot_bounds(data):
    """
    Вычисляет границы adjusted boxplot с учетом skewness-adjusted fences.
    """
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    iqr = q3 - q1
    _medcouple = medcouple(data)

    if _medcouple > 0:
        lower_fence = q1 - 1.5 * np.exp(-4 * _medcouple) * iqr
        upper_fence = q3 + 1.5 * np.exp(3 * _medcouple) * iqr
    else:
        lower_fence = q1 - 1.5 * np.exp(-3 * _medcouple) * iqr
        upper_fence = q3 + 1.5 * np.exp(4 * _medcouple) * iqr

    return lower_fence, upper_fence

def normalize_column(data):
    """
    Нормализация с использованием adjusted boxplot.
    """
    lower_fence, upper_fence = adjusted_boxplot_bounds(data)
    print(lower_fence)
    return (data - lower_fence) / (upper_fence - lower_fence)

# Генерация данных
np.random.seed(42)
data_normal = np.random.normal(loc=50, scale=10, size=10000)
data_skewed = np.random.exponential(scale=20, size=10000)
data_skewed = np.concatenate([data_skewed[5:], [200, 250, 300, -100, -50]])
data_with_outliers = np.concatenate([data_normal, [150, 160, 170]])

# Нормализация
df = pd.DataFrame({
    "Normal": data_normal,
    "Skewed": data_skewed,
    # "With_Outliers": data_with_outliers[3:],
})

normalized_df = df.apply(normalize_column)

plt.figure(figsize=(16, 4), dpi=250)

bins = np.linspace(-5, 200, 206)
bin_width = bins[1] - bins[0]  # Ширина одного бина

for col in df.columns:
    # plt.hist(df[col], bins=50, alpha=0.5, label=f'{col} - Original')
    # Вычисляем гистограммы без построения
    hist, _ = np.histogram(df[col], bins=bins)

    # Позиции столбиков для каждой гистограммы
    bin_centers = (bins[:-1] + bins[1:]) / 2

    # Смещение для каждого набора данных
    offset = bin_width / 4
    plt.bar(bin_centers - offset, hist, width=bin_width, align='center', alpha=0.2, label=f'{col}')
    plt.legend()
    plt.title(f"Histogram Before Normalization")
plt.xlim(-10, 200)
plt.show()

bins = np.linspace(-2, 2, 101)
bin_width = bins[1] - bins[0]  # Ширина одного бина


plt.figure(figsize=(16, 4), dpi=250)
for col in normalized_df.columns:
    # plt.hist(normalized_df[col], bins=50, alpha=0.5, label=f'{col} - Normalized')
    hist, _ = np.histogram(normalized_df[col], bins=bins)

    # Позиции столбиков для каждой гистограммы
    bin_centers = (bins[:-1] + bins[1:]) / 2
    # Смещение для каждого набора данных
    offset = bin_width / 2
    plt.bar(bin_centers - offset, hist, width=bin_width, align='center', label=f'{col}', alpha=0.2)
    plt.legend()
    plt.title(f"Histogram After Normalization")
plt.show()