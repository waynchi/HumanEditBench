def conjugate_gradient(A, b, x0=None, tol=1e-5, max_iter=None):
    """
    Solves Ax = b using the Conjugate Gradient method for symmetric positive-definite A.
    
    Parameters:
    A: ndarray, n x n matrix
    b: ndarray, right-hand side vector of length n
    x0: ndarray, initial guess (default zeros)
    tol: float, tolerance for convergence
    max_iter: int, maximum number of iterations (default len(b))
    
    Returns:
    x: ndarray, approximate solution
    """
    import numpy as np
    
    n = len(b)
    if x0 is None:
        x = np.zeros(n)
    else:
        x = x0.copy()
    
    if max_iter is None:
        max_iter = n
    
    r = b - A @ x
    p = r.copy()
    rsold = np.dot(r, r)
    
    for i in range(max_iter):
        Ap = A @ p
        alpha = rsold / np.dot(p, Ap)
        x += alpha * p
        r -= alpha * Ap
        rsnew = np.dot(r, r)
        
        if np.sqrt(rsnew) < tol:
            break
        
        p = r + (rsnew / rsold) * p
        rsold = rsnew
    
    return x