import numpy as np

def conj_grad(A, b, x0, tol=1e-10, max_iter=1000):
    """
    Metoda sprzężonych gradientów.

    Parametry:
    A (macierz): macierz współczynników
    b (wektor): wektor prawych stron
    x0 (wektor): wektor początkowy
    tol (liczba): tolerancja
    max_iter (liczba): maksymalna liczba iteracji

    Zwraca:
    x (wektor): rozwiazanie
    """
    x = x0
    r = b - np.dot(A, x0)
    p = r.copy()
    rsold = np.dot(r, r)

    for _ in range(max_iter):
        Ap = np.dot(A, p)
        alpha = rsold / np.dot(p, Ap)
        x += alpha * p
        r -= alpha * Ap
        rsnew = np.dot(r, r)
        if np.sqrt(rsnew) < tol:
            break
        p = r + (rsnew / rsold) * p
        rsold = rsnew

    return x

# Example usage
A = np.array([[4, 12, -16], [12, 37, -43], [-16, -43, 98]])
b = np.array([10, 25, -35])
x0 = np.array([0, 0, 0])

x = conj_grad(A, b, x0)
print(x)