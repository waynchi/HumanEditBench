import numpy as np

def grad_conjugado(A, b, x0, tol=1e-5, max_iter=1000):
    """
    Resuelve el sistema de ecuaciones lineales Ax = b utilizando el método de gradientes conjugados.

    Parámetros:
    A (numpy.array): Matriz de coeficientes.
    b (numpy.array): Vector de términos independientes.
    x0 (numpy.array): Vector inicial de aproximación.
    tol (float, opcional): Tolerancia para la convergencia. Por defecto es 1e-5.
    max_iter (int, opcional): Número máximo de iteraciones. Por defecto es 1000.

    Regresa:
    x (numpy.array): Vector solución del sistema de ecuaciones.
    """

    # Inicializa variables
    x = x0.copy()
    r = b - np.dot(A, x)
    p = r.copy()
    rsold = np.dot(r, r)

    # Itera hasta convergencia o máximo de iteraciones
    for _ in range(max_iter):
        # Calcula el producto Ap
        Ap = np.dot(A, p)

        # Calcula el coeficiente alpha
        alpha = rsold / np.dot(p, Ap)

        # Actualiza x y r
        x += alpha * p
        r -= alpha * Ap

        # Calcula el nuevo rsold
        rsnew = np.dot(r, r)

        # Comprueba la convergencia
        if np.sqrt(rsnew) < tol:
            break

        # Calcula el coeficiente beta
        beta = rsnew / rsold

        # Actualiza p
        p = r + beta * p

        # Actualiza rsold
        rsold = rsnew

    return x

# Ejemplo de uso
A = np.array([[4, 1], [1, 3]])
b = np.array([5, 6])
x0 = np.array([0, 0])

x = grad_conjugado(A, b, x0)
print("Solución:", x)