from langchain.llms import LLaMA
from langchain import PromptTemplate, LLMChain
from langchain.chains import LLMChain
import json

with open("Vuori_Final_Approval_2024_09_24.json", "r") as file:
    shap_values_json = json.load(file).get("shap_values")
with open("system.prompt", "r") as file:
    sys_prompt = file.read().strip()

prompt_template = PromptTemplate(
    input_variables=["shap_values", "sys_prompt"],
    template="{sys_prompt}\n{shap_values}",
)

llm = LLaMA(model_name="decapoda-research/llama-3.2-hf")

chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["shap_values", "sys_prompt"],
        template="{sys_prompt}\n{shap_values}",
    ),
)

output = chain({"shap_values": str(shap_values_json), "sys_prompt": sys_prompt})
print(output)