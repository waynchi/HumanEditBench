import random
import torch
from torchvision import transforms
from datasets import load_dataset
from PIL import Image
import numpy as np
from torchvision.datasets import CocoCaptions
import os

class AlignmentDatasetCreator:
    def __init__(self, sample_size=1000):
        self.sample_size = sample_size
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                              std=[0.229, 0.224, 0.225])
        ])

    def create_unrelated_pairs(self, image_text_pairs):
        """Создает несвязанные пары изображение-текст, перемешивая текстовые описания"""
        images, texts = zip(*image_text_pairs)
        shuffled_texts = list(texts)
        random.shuffle(shuffled_texts)
        return list(zip(images, shuffled_texts))

    def create_textual_pairs(self, dataset_name='quora'):
        """Создает семантически похожие текстовые пары, используя наборы данных парафраз."""
        dataset = load_dataset(dataset_name, split=f'train[:{self.sample_size}]')
        textual_pairs = []
        for item in dataset:
            if item['is_duplicate'] == 1:
                pair = (item['question1'], item['question2'])
                textual_pairs.append(pair)
        return textual_pairs[:self.sample_size]

    def create_visual_pairs(self, image_text_pairs):
        """Создает увеличенные пары изображений, сохраняя семантическое значение"""
        augmentation_transforms = transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.RandomRotation(15)
        ])

        visual_pairs = []
        for image, _ in image_text_pairs:
            if isinstance(image, Image.Image):
                augmented = augmentation_transforms(image)
                visual_pairs.append((image, augmented))
        return visual_pairs

    def load_mscoco_dataset(self):
        """Загружает и предварительно обрабатывает набор данных MSCOCO с улучшенной фильтрацией"""
        data_root = 'data'
        annotation_root = 'data/annotations'
        if not os.path.exists(data_root):
            os.makedirs(data_root)
            os.system('wget http://images.cocodataset.org/zips/train2014.zip -P data')
            os.system('unzip data/train2014.zip -d data')
            os.system('wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip -P data')
            os.system('unzip data/annotations_trainval2014.zip -d data/annotations')

        dataset = CocoCaptions(root=data_root, annFile=os.path.join(annotation_root, 'captions_train2014.json'))
        image_text_pairs = []
        for i, _ in enumerate(dataset):
            img, caption = dataset[i]
            best_caption = max(caption, key=len)
            if len(best_caption.split()) >= 5:  # Отфильтровать слишком короткие подписи
                image_text_pairs.append((img, best_caption))
            if len(image_text_pairs) >= self.sample_size:
                break
        return image_text_pairs

def main():
    # Инициализация создателя набора данных
    creator = AlignmentDatasetCreator(sample_size=100)

    # Загрузить и создать наборы данных
    print("Loading MSCOCO dataset...")
    image_text_pairs = creator.load_mscoco_dataset()

    print("Creating unrelated pairs...")
    unrelated_pairs = creator.create_unrelated_pairs(image_text_pairs)

    print("Creating textual pairs...")
    textual_pairs = creator.create_textual_pairs()

    print("Creating visual pairs...")
    visual_pairs = creator.create_visual_pairs(image_text_pairs)

    # Вывести образец из каждого набора данных
    print("Dataset Samples:")
    print(f"Image-Text Pair: {image_text_pairs[0]}")
    print(f"Unrelated Pair: {unrelated_pairs[0]}")
    print(f"Textual Pair: {textual_pairs[0]}")
    print(f"Visual Pair: {visual_pairs[0]}")

if __name__ == "__main__":
    main()
