import torch
from transformers import TrainerCallback, Trainer
import numpy as np
import re
from datasets import Dataset
import os

import json
import time  # Importing the time module to measure performance

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    get_linear_schedule_with_warmup,
)
from peft import (
    get_peft_model,
    LoraConfig,
    PeftModel,
    TaskType,
)
from trl.trainer import ConstantLengthDataset
from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM
from torch.utils.data import DataLoader

from my_eval import factual_score
from my_datasets import gen_mod_dataset, format_and_load_mod_data, load_sample_data
from utils import clear_directory, merge_lora_model

from dotenv import load_dotenv


import time

load_dotenv()

DATA_SAVE_PATH = os.getenv("DATA_SAVE_PATH")
MODEL_PATH = os.getenv("MODEL_PATH")

# Mocks
def factual_score_dataloader(*args):
    pass

batch_size = 16

def default_data_collator(*args):
    pass

x = {}

def initialize_model_and_tokenizer(
    model_name_or_path,
    tokenizer_name_or_path=None,
    config=None,
):
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)
    if config:
        model = get_peft_model(model, config)
        # model.print_trainable_parameters()
    if tokenizer_name_or_path is None:
        tokenizer_name_or_path = model_name_or_path
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "left"
    return model, tokenizer


def data_collator(batch):

    inputs = {
        # .to(device),
        "input_ids": torch.stack([item["input_ids"] for item in batch]),
        # .to(device),
        "labels": torch.stack([item["labels"] for item in batch]),
    }
    return inputs


def formatting_prompts_func(example):
    output_texts = []
    for i in range(len(example["instruction"])):
        text = f"### Question: {x['question']} ### Answer: {x['answer']}"
        output_texts.append(text)
    return output_texts


def train_model(
    dataset, model, tokenizer, training_args, callbacks=None, verbose=False
):
    # Split dataset
    train_test_split = dataset.train_test_split(test_size=0.2)

    # Create ConstantLengthDataset instances
    train_dataset = ConstantLengthDataset(
        tokenizer,
        train_test_split["train"],
        formatting_func=lambda x: f"### Question: {x['question']} ### Answer: {x['answer']}",
        seq_length=18,
        num_of_sequences=20,
    )

    eval_dataset = ConstantLengthDataset(
        tokenizer,
        train_test_split["test"],
        formatting_func=lambda x: f"### Question: {x['question']} ### Answer: {x['answer']}",
        seq_length=18,
        num_of_sequences=20,
    )

    # optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)

    # num_epochs = training_args.num_train_epochs
    # num_warmup_steps = int(0.1 * len(train_dataset))  # 10% of training steps
    # total_training_steps = len(train_dataset) * num_epochs
    # # Set up the scheduler
    # scheduler = get_linear_schedule_with_warmup(
    #     optimizer,
    #     num_warmup_steps=num_warmup_steps,
    #     num_training_steps=total_training_steps,
    # )

    collator = DataCollatorForCompletionOnlyLM(
        " ### Answer: ",
        tokenizer=tokenizer,
    )  # Must match formatting_func

    trainer = SFTTrainer(
        model=model,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        # optimizers=None,#(optimizer, scheduler),
        data_collator=data_collator,  # Use the collator you defined
        # formatting_func=formatting_prompts_func,
        packing=False,
        callbacks=callbacks,
        args=SFTConfig(**training_args.to_dict()),
    )

    if verbose:
        print("Training init done. Starting training...")
        start_time = time.time()

    trainer.train()

    if verbose:
        print(f"Training completed in {time.time() - start_time:.2f} seconds.")
        print("Starting evaluation...")
        start_time = time.time()

    trainer.evaluate()

    if verbose:
        print(f"Evaluation completed in {time.time() - start_time:.2f} seconds.")

    return trainer


def setup_training_args(
    save_path,
    model_name,
    learning_rate,
    num_epochs,
    total_train_examples,
    batch_size=1024,
    footer="",
):
    if len(footer) == 0:
        checkpoint_dir = os.path.join(save_path, model_name + "_checkpoints")
        logging_dir = os.path.join(save_path, model_name + "_logs")
    else:
        checkpoint_dir = os.path.join(save_path, model_name + f"_checkpoints_{footer}")
        logging_dir = os.path.join(save_path, model_name + f"_logs_{footer}")

    clear_directory(checkpoint_dir)

    # Calculate the steps per epoch based on total number of training examples and batch size
    steps_per_epoch = total_train_examples // batch_size

    # Calculate eval_steps, save_steps, and logging_steps based on the steps per epoch
    eval_steps = max(
        1, steps_per_epoch // 10
    )  # Evaluate 10 times per epoch, at least once per epoch
    save_steps = eval_steps * 10  # Save after every 10 evaluation steps
    logging_steps = max(
        1, steps_per_epoch // 20
    )  # Log 20 times per epoch, at least once per epoch

    return TrainingArguments(
        output_dir=checkpoint_dir,
        learning_rate=learning_rate,
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        num_train_epochs=num_epochs,
        eval_steps=eval_steps,
        save_steps=save_steps,
        logging_steps=logging_steps,
        save_total_limit=2,  # Keep only the 2 best checkpoints
        weight_decay=0.01,
        evaluation_strategy="steps",  # Changed to steps to make use of eval_steps
        logging_strategy="steps",
        save_strategy="steps",  # Changed to steps to make use of save_steps
        logging_dir=logging_dir,  # Uncomment this if you define a logging directory
        report_to="none",  # Report to tensorboard for visual monitoring
        load_best_model_at_end=True,
        dataloader_pin_memory=False,
    )



class FactualAccuracyCallbackBETTER(TrainerCallback):
    """
    A callback to evaluate and log the factual accuracy of the model during training.
    """

    def __init__(
        self, model, tokenizer, dataset, verbose=False, output_format=False
    ):
        super().__init__()
        self.model = model
        self.tokenizer = tokenizer
        self.n_samp = len(dataset)
        self.verbose = verbose
        self.output_format = output_format
        self.dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=True,
            collate_fn=default_data_collator  # Collate function for padding and formatting
        )

    def on_log(self, args, state, control, model=None, **kwargs):
        """
        Called after logging the last logs.
        """
        if model is not None:
            self.model = model
        elif self.model is None:
            print("Model is not available.")
            return

        if (
            state.is_local_process_zero
        ):  # Only log from the main process every 100 steps
            start_time = time.time()
            try:
                if self.output_format:
                    fact_results, format_hard_results, format_soft_results = (
                        factual_score_dataloader(
                            model=self.model,
                            tokenizer=self.tokenizer,
                            dataloader=self.dataloader,
                            output_format=self.output_format,
                        )
                    )
                    # Calculate and log the formatted result
                    format_hard_avg = sum(format_hard_results) / self.n_samp
                    format_soft_avg = sum(format_soft_results) / self.n_samp
                else:
                    fact_results = factual_score_dataloader(
                        model=self.model,
                        tokenizer=self.tokenizer,
                        dataloader=self.dataloader,
                        n_samples=self.n_samp,
                    )
                factual_accuracy_avg = sum(fact_results) / self.n_samp

                if len(state.log_history) > 0:
                    state.log_history[-1]["factual_accuracy"] = factual_accuracy_avg
                    if self.output_format:
                        state.log_history[-1]["format_hard"] = format_hard_avg
                        state.log_history[-1]["format_soft"] = format_soft_avg
                else:
                    print("No log entries available to update.")

                time_taken = time.time() - start_time
                if self.verbose:
                    print(
                        f"[TIME] {time_taken:.2f} seconds: Model evaluated on FactualAccuracy."
                    )
            except Exception as e:
                print(f"Error during factual accuracy evaluation: {e}")



class FactualAccuracyCallback(TrainerCallback):
    """
    A callback to evaluate and log the factual accuracy of the model during training.
    """

    def __init__(
        self, model, tokenizer, df, n_samp=30, verbose=False, output_format=False
    ):
        super().__init__()
        self.model = model
        self.tokenizer = tokenizer
        self.df = df
        self.n_samp = n_samp
        self.verbose = verbose
        self.output_format = output_format

    def on_log(self, args, state, control, model=None, **kwargs):
        """
        Called after logging the last logs.
        """
        if model is not None:
            self.model = model
        elif self.model is None:
            print("Model is not available.")
            return

        if (
            state.is_local_process_zero
        ):  # Only log from the main process every 100 steps
            start_time = time.time()
            try:
                with torch.no_grad():
                    if self.output_format:
                        fact_results, format_hard_results, format_soft_results = (
                            factual_score(
                                self.model,
                                self.tokenizer,
                                self.df,
                                n_samples=self.n_samp,
                                output_format=self.output_format,
                            )
                        )
                        # Calculate and log the formatted result
                        format_hard_avg = sum(format_hard_results) / self.n_samp
                        format_soft_avg = sum(format_soft_results) / self.n_samp
                    else:
                        fact_results = factual_score(
                            self.model,
                            self.tokenizer,
                            self.df,
                            n_samples=self.n_samp,
                            output_format=self.output_format,
                        )
                    factual_accuracy_avg = sum(fact_results) / self.n_samp

                if len(state.log_history) > 0:
                    state.log_history[-1]["factual_accuracy"] = factual_accuracy_avg
                    if self.output_format:
                        state.log_history[-1]["format_hard"] = format_hard_avg
                        state.log_history[-1]["format_soft"] = format_soft_avg
                else:
                    print("No log entries available to update.")

                time_taken = time.time() - start_time
                if self.verbose:
                    print(
                        f"[TIME] {time_taken:.2f} seconds: Model evaluated on FactualAccuracy."
                    )
            except Exception as e:
                print(f"Error during factual accuracy evaluation: {e}")


def fine_tuned_specific_layers(
    n_rows=1000,
    mod=4,
    model_name_or_path="EleutherAI/pythia-31M",
    tokenizer_name_or_path=None,
    learning_rate=5.0e-3,
    num_epochs=15,
    batch_size=32,
    save_dir="",
    verbose=True,  # Adding the verbose parameter here
    model_path=MODEL_PATH,
    special_format=True,
):
    # Initialize a variable to keep track of the start time
    start_time = time.time()

    if verbose:
        print("Starting the dataset generation process.")

    gen_mod_dataset(
        n_rows=n_rows,
        mod=mod,
        lower_bound_gen=0,
        higher_bound_gen=100,
        special_format=special_format,
    )

    if verbose:
        print(
            f"[TIME] {time.time() - start_time:>8.2f} seconds: Dataset generation completed."
        )

    start_time = time.time()
    mod_dataset = format_and_load_mod_data(mod=mod)

    if tokenizer_name_or_path is None:
        tokenizer_name_or_path = model_name_or_path
        if verbose:
            print(
                f"No tokenizer specified, using the model path for tokenizer: {tokenizer_name_or_path}"
            )

    start_time = time.time()
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)
    if verbose:
        print(
            f"[TIME] {time.time() - start_time:>8.2f} seconds: Loading model and tokenizer completed."
        )

    num_layers = model.config.num_hidden_layers

    layers = list(
        range(1, num_layers)
    )  # TODO: last layer alone cannot work, but i works jointly with others
    layer_combinations = []

    # Generate contiguous combinations up to 3 layers
    for i in range(len(layers)):
        for j in range(1, 4):  # 1, 2, or 3 layers
            if i + j <= len(layers):
                layer_combinations.append(layers[i : i + j])
    for layers in layer_combinations:
        start_time = time.time()
        footer = "layers_" + "_".join([str(x) for x in layers])

        save_path = os.path.join(model_path, save_dir)
        if not os.path.exists(save_path):
            os.makedirs(save_path)
            if verbose:
                print(f"Directory {save_path} created.")

        if verbose:
            print(f"Configuring fine-tuning for layer combination: {footer}")

        peft_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            inference_mode=False,
            r=32,
            lora_alpha=32,
            lora_dropout=0.1,
            layers_to_transform=layers,
        )

        model, tokenizer = initialize_model_and_tokenizer(
            model_name_or_path, tokenizer_name_or_path, config=peft_config
        )

        if verbose:
            print(
                f"[TIME] {time.time() - start_time:>8.2f} seconds: Model and tokenizer initialization completed."
            )

        start_time = time.time()
        eval_df = load_sample_data(mod=mod, n_samples=100)
        if verbose:
            print(
                f"[TIME] {time.time() - start_time:>8.2f} seconds: Evaluation sample data loaded."
            )

        model_name = model_name_or_path.split("/")[-1]
        training_args = setup_training_args(
            os.path.join(save_path, "checkpoints"),
            model_name,
            learning_rate=learning_rate,
            num_epochs=num_epochs,
            footer=footer,
            batch_size=batch_size,
            total_train_examples=n_rows,
        )

        start_time = time.time()
        if verbose:
            print("Starting model training.")
        trainer = train_model(
            mod_dataset,
            model,
            tokenizer,
            training_args,
            callbacks=[
                FactualAccuracyCallback(
                    model, tokenizer, eval_df, n_samp=100, output_format=True
                )
            ],
            verbose=verbose,
        )
        if verbose:
            print(
                f"[TIME] {time.time() - start_time:>8.2f}: Model training completed in  seconds."
            )

        model_save_name = f"{model_name}_trained_{footer}"
        save_path = os.path.join(save_path, model_save_name)
        if verbose:
            print(f"Saving model to {save_path}.")

        start_time = time.time()
        trainer.save_model(output_dir=save_path)
        if verbose:
            print(f"[TIME] {time.time() - start_time:>8.2f}: Model saved in  seconds.")

        # Access the log history
        log_history = trainer.state.log_history

        # Save the training logs
        logs_save_path = os.path.join(save_path, "training_logs.json")
        with open(logs_save_path, "w") as f:
            json.dump(log_history, f, indent=4)

        if verbose:
            print(f"Training logs saved to {logs_save_path}.")

    # Merge models
    to_merge = [
        x
        for x in os.listdir(os.path.join(model_path, save_dir))
        if all([a not in x for a in ["_checkpoints", "merged"]])
    ]
    to_merge = [x for x in to_merge if "_trained_" in x]
    for model_name in to_merge:
        print("C", model_name)
        merge_lora_model(
            model_name=model_name,
            model_load_path=os.path.join(model_path, save_dir),
            model_save_path=os.path.join(model_path, save_dir),
        )
        print(model_name, "MERGED !")


def fine_tuned_simple(
    n_rows=1000,
    mod=4,
    model_name_or_path="EleutherAI/pythia-31M",
    tokenizer_name_or_path=None,
    learning_rate=5.0e-3,
    num_epochs=15,
    batch_size=32,
    save_dir="",
    verbose=True,
    model_path=MODEL_PATH,
    special_format=True,
    layers=[2],
):
    # Initialize a variable to keep track of the start time

    if verbose:
        print("Starting the dataset generation process.")

    gen_mod_dataset(
        n_rows=n_rows,
        mod=mod,
        lower_bound_gen=0,
        higher_bound_gen=100,
        special_format=special_format,
    )

    mod_dataset = format_and_load_mod_data(mod=mod, dataset_type="train")

    if tokenizer_name_or_path is None:
        tokenizer_name_or_path = model_name_or_path
        if verbose:
            print(
                f"No tokenizer specified, using the model path for tokenizer: {tokenizer_name_or_path}"
            )

    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)

    num_layers = model.config.num_hidden_layers

    footer = "layers_" + "_".join([str(x) for x in layers])

    save_path = os.path.join(model_path, save_dir)
    if not os.path.exists(save_path):
        os.makedirs(save_path)
        if verbose:
            print(f"Directory {save_path} created.")

    if verbose:
        print(f"Configuring fine-tuning for layer combination: {footer}")

    peft_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        inference_mode=False,
        r=32,
        lora_alpha=32,
        lora_dropout=0.1,
        layers_to_transform=layers,
    )

    model, tokenizer = initialize_model_and_tokenizer(
        model_name_or_path, tokenizer_name_or_path, config=peft_config
    )

    def tokenize_function(examples):
        # Tokenize the input prompt
        tokenized_input = tokenizer(
            examples["question"],
            padding="max_length",
            truncation=True,
            max_length=512,  # Adjust based on your model's max input length
        )

        # Tokenize the answer to form the labels
        tokenized_labels = tokenizer(
            examples["answer"],
            padding="max_length",
            truncation=True,
            max_length=128,  # Adjust based on your answer length
        )

        # Assign the tokenized labels
        tokenized_input["labels"] = tokenized_labels["input_ids"]

        return tokenized_input

    tokenized_dataset = mod_dataset.map(tokenize_function, batched=True)
    eval_dataset = format_and_load_mod_data(mod=mod, dataset_type="test", n_samples=100)
    tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)

    # Training Args
    model_name = model_name_or_path.split("/")[-1]
    if len(footer) == 0:
        checkpoint_dir = os.path.join(save_path, model_name + "_checkpoints")
        logging_dir = os.path.join(save_path, model_name + "_logs")
    else:
        checkpoint_dir = os.path.join(save_path, model_name + f"_checkpoints_{footer}")
        logging_dir = os.path.join(save_path, model_name + f"_logs_{footer}")
    total_train_examples = n_rows
    steps_per_epoch = total_train_examples // batch_size
    eval_steps = max(1, steps_per_epoch // 10)
    save_steps = eval_steps * 10  # Save after every 10 evaluation steps
    logging_steps = max(1, steps_per_epoch // 20)

    training_args = TrainingArguments(
        output_dir=checkpoint_dir,
        learning_rate=learning_rate,
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        num_train_epochs=num_epochs,
        eval_steps=eval_steps,
        save_steps=save_steps,
        logging_steps=logging_steps,
        save_total_limit=2,
        weight_decay=0.01,
        evaluation_strategy="steps",
        logging_strategy="steps",
        save_strategy="steps",
        logging_dir=logging_dir,
        report_to="none",
        load_best_model_at_end=True,
    )

    start_time = time.time()
    if verbose:
        print("Starting model training.")

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_dataset,
        eval_dataset=tokenized_eval_dataset,
        callbacks=[
            FactualAccuracyCallbackBETTER(
                model, tokenizer, eval_dataset, output_format=True
            )
        ],
    )
    trainer.train()
    if verbose:
        print(
            f"[TIME] {time.time() - start_time:>8.2f}: Model training completed in  seconds."
        )

    model_save_name = f"{model_name}_trained_{footer}"
    save_path = os.path.join(save_path, model_save_name)
    if verbose:
        print(f"Saving model to {save_path}.")

    trainer.save_model(output_dir=save_path)
    # Access the log history
    log_history = trainer.state.log_history

    # Save the training logs
    logs_save_path = os.path.join(save_path, "training_logs.json")
    with open(logs_save_path, "w") as f:
        json.dump(log_history, f, indent=4)

    if verbose:
        print(f"Training logs saved to {logs_save_path}.")