import numpy as np

def conjugate_gradient(A, b, x0=None, tol=1e-8, max_iter=None):
    """
    Solves the linear system Ax = b using the conjugate gradient method.
    
    Parameters:
    A : callable or 2D array
        If callable, A is a function that takes a vector and returns the matrix-vector product A*x.
        If 2D array, A is the matrix.
    b : 1D array
        The right-hand side vector.
    x0 : 1D array, optional
        Initial guess. If None, set to zero vector.
    tol : float, optional
        Tolerance for convergence. The iteration stops when the norm of the residual is below tol.
    max_iter : int, optional
        Maximum number of iterations. If None, set to 10 * len(b).
        
    Returns:
    x : 1D array
        The solution vector.
    """
    n = len(b)
    if x0 is None:
        x = np.zeros(n)
    else:
        x = x0.copy()
        
    if max_iter is None:
        max_iter = 10 * n
        
    # Compute initial residual
    if callable(A):
        r = b - A(x)
    else:
        r = b - np.dot(A, x)
        
    p = r.copy()
    rs_old = np.dot(r, r)
    
    if np.sqrt(rs_old) < tol:
        return x
        
    for i in range(max_iter):
        # Compute Ap
        if callable(A):
            Ap = A(p)
        else:
            Ap = np.dot(A, p)
            
        alpha = rs_old / np.dot(p, Ap)
        x = x + alpha * p
        r = r - alpha * Ap
        rs_new = np.dot(r, r)
        
        # Check for convergence
        if np.sqrt(rs_new) < tol:
            break
            
        beta = rs_new / rs_old
        p = r + beta * p
        rs_old = rs_new
        
    return x