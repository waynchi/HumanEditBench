python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import requests

# Создать сессию Spark
spark = SparkSession.builder.appName("EscrituraParquetADL2").getOrCreate()

# Получить данные из API и распарсить их
# Замените <your_api_url> на реальный URL вашего API
api_url = "<your_api_url>"
try:
    response = requests.get(api_url)
    response.raise_for_status()  # Проверить успешность запроса
    data = response.json()  # Распарсить JSON-ответ
except requests.exceptions.RequestException as e:
    print(f"Ошибка при получении данных из API: {e}")
    data = []  # В случае ошибки использовать пустой список

# Создать DataFrame из данных
df = spark.createDataFrame(data)

# Настроить подключение к ADL2 с использованием идентификатора Microsoft ID
# В блокноте Synapse не нужно явно указывать учетные данные
# Spark будет использовать управляемую идентичность блокнота для аутентификации.

# Указать путь к контейнеру и папке в ADL2
container_name = "<your_container_name>"  # Заменить на имя вашего контейнера
folder_path = "<your_folder_path>"  # Заменить на путь к папке внутри контейнера
adl2_path = f"abfss://{container_name}@{<your_storage_account_name>}.dfs.core.windows.net/{folder_path}"

# Записать DataFrame в формате parquet в ADL2
df.write.parquet(adl2_path, mode="overwrite")

# Опционально: прочитать файл parquet для проверки
df_leido = spark.read.parquet(adl2_path)
df_leido.show()

# Остановить сессию Spark
spark.stop()