import torch
import torch.nn as nn

class SimpleConvNet1(nn.Module):
    """
    A simple convolutional neural network.

    The main issue with the original code was that the __init__ method required a
    pre-calculated `flattened_size` for the first linear layer. This makes the
    model rigid and difficult to use with different input image sizes.

    This corrected implementation calculates the `flattened_size` dynamically within
    the __init__ method. It performs a "dummy" forward pass with a tensor of zeros
    shaped like the input data to determine the output shape of the convolutional
    layers. This makes the model flexible and self-contained. The constructor
    now accepts the input image height and width, with default values provided.
    """
    def __init__(self, height=32, width=32):
        super().__init__()

        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 32, 3),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        self.conv2 = nn.Sequential(
            nn.Conv2d(32, 64, 3),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        # Create a dummy tensor with the specified input size
        # and pass it through the convolutional layers to determine
        # the flattened size for the linear layer.
        with torch.no_grad():
            dummy_input = torch.zeros(1, 3, height, width)
            conv_output = self.conv2(self.conv1(dummy_input))
            flattened_size = conv_output.flatten(1).shape[1]

        self.flatten = nn.Flatten()
        self.fc1 = nn.Sequential(
            nn.Linear(flattened_size, 512),  # Use the dynamically calculated size
            nn.ReLU(),
            nn.Linear(512, 3)
        )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        return x