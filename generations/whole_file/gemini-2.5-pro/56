import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import skew

# def medcouple(data):
#     data = np.sort(data)  # Сортируем данные
#     n = len(data)
#     median = np.median(data)

#     # Разделяем данные на меньше медианы и больше медианы
#     left = data[data <= median]
#     right = data[data >= median]

#     # Функция ядра h(xi, xj)
#     def h(xi, xj):
#         if xi != xj:
#             return ((xj - median) - (median - xi)) / (xj - xi)
#         return 0  # Хотя xi != xj должно исключать этот случай

#     # Специальное ядро для случаев с повторениями медианы
#     def special_h(i, j, k):
#         if i + j - 1 < k:
#             return -1
#         elif i + j - 1 == k:
#             return 0
#         elif i + j - 1 > k:
#             return 1

#     # Генерация всех возможных h(xi, xj)
#     h_values = []
#     k = len(data[data == median])  # Количество повторяющихся значений медианы
#     if k > 1:  # Обработка случая с совпадающими медианами
#         for i, xi in enumerate(left):
#             for j, xj in enumerate(right):
#                 if xi == xj == median:
#                     h_values.append(special_h(i, j, k))
#                 else:
#                     h_values.append(h(xi, xj))
#     else:
#         for xi in left:
#             for xj in right:
#                 h_values.append(h(xi, xj))

#     # Возвращаем медиану всех значений h
#     return np.median(h_values)
# Нужно ускорить и переписать функцию medcouple 

def medcouple(data):
    """
    Calculates the medcouple, a robust measure of skewness.
    This implementation is vectorized with numpy for performance and fixes the ValueError
    caused by applying conditional logic to full arrays.
    """
    # Ensure data is a sorted numpy array
    data = np.sort(np.asarray(data))
    n = len(data)
    
    # Handle empty input to avoid errors
    if n == 0:
        return np.nan

    median = np.median(data)

    # Split data into values less/equal and greater/equal to the median
    left = data[data <= median]
    right = data[data >= median]

    # Count of repeated median values
    k = np.count_nonzero(data == median)

    # Create grids of all pairs (xi, xj) using broadcasting
    xi, xj = np.meshgrid(left, right, indexing='ij')

    # The vectorized approach avoids python loops and conditional statements on arrays,
    # which was the cause of the original ValueError.

    # Case 1: More than one median value requires a special kernel
    if k > 1:
        # Create grids of indices (i, j) for the special kernel
        left_indices = np.arange(len(left))
        right_indices = np.arange(len(right))
        i, j = np.meshgrid(left_indices, right_indices, indexing='ij')

        # Vectorized implementation of the special kernel for repeated medians.
        # This is equivalent to the original special_h logic:
        # if i+j-1 < k: -1; elif i+j-1 == k: 0; else: 1
        # It's calculated for all i,j pairs and will be selected later.
        special_h_matrix = np.sign((i + j - 1) - k).astype(float)

        # Vectorized implementation of the standard kernel h(xi, xj).
        # We pre-calculate this for all pairs.
        numerator = (xj - median) - (median - xi)
        denominator = xj - xi
        
        # np.divide handles the case where denominator is 0 (xi == xj) by outputting 0.
        h_normal_matrix = np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=(denominator != 0))
        
        # Use np.where to select values from the appropriate kernel matrix.
        # This is safe now because both matrices are pre-calculated before the selection.
        condition_mask = (xi == median) & (xj == median)
        h_matrix = np.where(condition_mask, special_h_matrix, h_normal_matrix)
    
    # Case 2: No (or one) median value, standard kernel is sufficient
    else:
        # Vectorized implementation of the standard kernel h(xi, xj).
        numerator = (xj - median) - (median - xi)
        denominator = xj - xi
        
        # np.divide handles the case where denominator is 0 (xi == xj) by outputting 0.
        h_matrix = np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=(denominator != 0))

    # Flatten the matrix of h values and return their median
    return np.median(h_matrix.flatten())

def adjusted_boxplot_bounds(data):
    """
    Вычисляет границы adjusted boxplot с учетом skewness-adjusted fences.
    """
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    iqr = q3 - q1
    _medcouple = medcouple(data)

    if _medcouple > 0:
        lower_fence = q1 - 1.5 * np.exp(-4 * _medcouple) * iqr
        upper_fence = q3 + 1.5 * np.exp(3 * _medcouple) * iqr
    else:
        lower_fence = q1 - 1.5 * np.exp(-3 * _medcouple) * iqr
        upper_fence = q3 + 1.5 * np.exp(4 * _medcouple) * iqr

    return lower_fence, upper_fence

def normalize_column(data):
    """
    Нормализация с использованием adjusted boxplot.
    """
    lower_fence, upper_fence = adjusted_boxplot_bounds(data)
    print(lower_fence)
    return (data - lower_fence) / (upper_fence - lower_fence)

# Генерация данных
np.random.seed(42)
data_normal = np.random.normal(loc=50, scale=10, size=10000)
data_skewed = np.random.exponential(scale=20, size=10000)
data_skewed = np.concatenate([data_skewed[5:], [200, 250, 300, -100, -50]])
data_with_outliers = np.concatenate([data_normal, [150, 160, 170]])

# Нормализация
df = pd.DataFrame({
    "Normal": data_normal,
    "Skewed": data_skewed,
    # "With_Outliers": data_with_outliers[3:],
})

normalized_df = df.apply(normalize_column)

plt.figure(figsize=(16, 4), dpi=250)

bins = np.linspace(-5, 200, 206)
bin_width = bins[1] - bins[0]  # Ширина одного бина

for col in df.columns:
    # plt.hist(df[col], bins=50, alpha=0.5, label=f'{col} - Original')
    # Вычисляем гистограммы без построения
    hist, _ = np.histogram(df[col], bins=bins)

    # Позиции столбиков для каждой гистограммы
    bin_centers = (bins[:-1] + bins[1:]) / 2

    # Смещение для каждого набора данных
    offset = bin_width / 4
    plt.bar(bin_centers - offset, hist, width=bin_width, align='center', alpha=0.2, label=f'{col}')
    plt.legend()
    plt.title(f"Histogram Before Normalization")
plt.xlim(-10, 200)
plt.show()

bins = np.linspace(-2, 2, 101)
bin_width = bins[1] - bins[0]  # Ширина одного бина


plt.figure(figsize=(16, 4), dpi=250)
for col in normalized_df.columns:
    # plt.hist(normalized_df[col], bins=50, alpha=0.5, label=f'{col} - Normalized')
    hist, _ = np.histogram(normalized_df[col], bins=bins)

    # Позиции столбиков для каждой гистограммы
    bin_centers = (bins[:-1] + bins[1:]) / 2
    # Смещение для каждого набора данных
    offset = bin_width / 2
    plt.bar(bin_centers - offset, hist, width=bin_width, align='center', label=f'{col}', alpha=0.2)
    plt.legend()
    plt.title(f"Histogram After Normalization")
plt.show()