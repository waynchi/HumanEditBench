import random
import torch
from torchvision import transforms
from datasets import load_dataset
from PIL import Image
import numpy as np

class AlignmentDatasetCreator:
    def __init__(self, sample_size=1000):
        self.sample_size = sample_size
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                              std=[0.229, 0.224, 0.225])
        ])
    def create_unrelated_pairs(self, image_text_pairs):
        """Creates unrelated image-text pairs by shuffling the text descriptions"""
        images, texts = zip(*image_text_pairs)
        shuffled_texts = list(texts)
        random.shuffle(shuffled_texts)
        return list(zip(images, shuffled_texts))

    def create_textual_pairs(self, dataset_name='quora'):
        """Creates semantically similar text pairs using paraphrase datasets"""
        try:
            dataset = load_dataset(dataset_name, split=f'train[:{self.sample_size}]')
            textual_pairs = []
            for item in dataset:
                if item['is_duplicate'] == 1:
                    pair = (item['question1'], item['question2'])
                    textual_pairs.append(pair)
            return textual_pairs[:self.sample_size]
        except Exception as e:
            print(f"Warning: Could not load {dataset_name} dataset: {e}")
            # Return dummy text pairs as fallback
            dummy_pairs = [
                ("What is artificial intelligence?", "How do you define AI?"),
                ("How does machine learning work?", "What is the process of ML?"),
                ("What is deep learning?", "Can you explain neural networks?")
            ]
            return dummy_pairs[:min(self.sample_size, len(dummy_pairs))]
            
    def create_visual_pairs(self, image_text_pairs):
        """Creates augmented image pairs while maintaining semantic meaning"""
        augmentation_transforms = transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.RandomRotation(15)
        ])
        
        visual_pairs = []
        for image, _ in image_text_pairs:
            if isinstance(image, Image.Image):
                augmented = augmentation_transforms(image)
                visual_pairs.append((image, augmented))
        return visual_pairs

    def load_mscoco_dataset(self):
        """Loads and preprocesses MSCOCO dataset with improved filtering and error handling"""
        try:
            # Try the original MSCOCO dataset first
            dataset = load_dataset(
                "shunk031/MSCOCO",
                year=2014,
                coco_task="captions",
                split='train',
                streaming=True
            )
            dataset = dataset.take(self.sample_size)

            image_text_pairs = []
            for item in dataset:
                try:
                    # Select most descriptive caption based on length
                    best_caption = max(item["captions"], key=len)
                    if len(best_caption.split()) >= 5:  # Filter out too short captions
                        image_text_pairs.append((item["image"], best_caption))
                except Exception as e:
                    print(f"Warning: Skipping item due to error: {e}")
                    continue
                    
            if len(image_text_pairs) > 0:
                return image_text_pairs
                
        except Exception as e:
            print(f"Warning: Could not load MSCOCO dataset: {e}")
        
        # Fallback to a different dataset
        try:
            print("Trying alternative dataset: nlphuji/flickr30k")
            dataset = load_dataset("nlphuji/flickr30k", split=f'test[:{self.sample_size}]')
            
            image_text_pairs = []
            for item in dataset:
                try:
                    # Flickr30k has different structure
                    caption = item["caption"][0] if isinstance(item["caption"], list) else item["caption"]
                    if len(caption.split()) >= 5:
                        image_text_pairs.append((item["image"], caption))
                except Exception as e:
                    print(f"Warning: Skipping item due to error: {e}")
                    continue
                    
            if len(image_text_pairs) > 0:
                return image_text_pairs
                
        except Exception as e:
            print(f"Warning: Could not load Flickr30k dataset: {e}")
        
        # Final fallback - create dummy data with synthetic images
        print("Creating dummy dataset as fallback")
        image_text_pairs = []
        dummy_captions = [
            "A cat sitting on a windowsill looking outside",
            "A red car parked on a busy street",
            "Children playing in a green park with trees",
            "A beautiful sunset over the ocean waves",
            "A dog running through a field of flowers"
        ]
        
        for i in range(min(self.sample_size, len(dummy_captions))):
            # Create a simple dummy image
            dummy_image = Image.new('RGB', (224, 224), color=(100 + i*30, 150, 200))
            image_text_pairs.append((dummy_image, dummy_captions[i]))
            
        return image_text_pairs

def main():
    # Initialize dataset creator
    creator = AlignmentDatasetCreator(sample_size=100)
    
    # Load and create datasets
    print("Loading MSCOCO dataset...")
    image_text_pairs = creator.load_mscoco_dataset()
    
    print("Creating unrelated pairs...")
    unrelated_pairs = creator.create_unrelated_pairs(image_text_pairs)
    
    print("Creating textual pairs...")
    textual_pairs = creator.create_textual_pairs()
    
    print("Creating visual pairs...")
    visual_pairs = creator.create_visual_pairs(image_text_pairs)
    
    # Print sample from each dataset
    print("Dataset Samples:")
    print(f"Image-Text Pair: {image_text_pairs[0]}")
    print(f"Unrelated Pair: {unrelated_pairs[0]}")
    print(f"Textual Pair: {textual_pairs[0]}")
    print(f"Visual Pair: {visual_pairs[0]}")

if __name__ == "__main__":
    main()